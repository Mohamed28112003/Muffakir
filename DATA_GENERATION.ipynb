{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/Mohamed28112003/Muffakir/blob/main/DATA_GENERATION.ipynb",
      "authorship_tag": "ABX9TyPCSdlBqVRo5tLgumGkN/CM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed28112003/Muffakir/blob/main/DATA_GENERATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s10wH1WwjUpq"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n",
        "!pip install -U bitsandbytes\n",
        "!pip install langchain_groq\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "import pandas as pd\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain_groq import ChatGroq\n",
        "import time\n",
        "from langchain.schema import HumanMessage\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "TeZkh-7pORZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your final data frame"
      ],
      "metadata": {
        "id": "w76W90_BL4RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "NmZjXh7fLyc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_splitter_recursive = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Adjust chunk size based on content length\n",
        "    chunk_overlap=0,  # No overlap needed\n",
        "    separators=[\"Page number\"] # Split at answer or next question\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load documents from the specified directory\n",
        "data_loader = TextLoader('filepath')\n",
        "data = data_loader.load_and_split(text_splitter=text_splitter_recursive) # Load documents\n",
        "print(f\"Documents : {len(data)}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47AoLdwJouSc",
        "outputId": "143c10ba-6fac-40de-b1df-a9ba74d6e1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents : 796.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[1].page_content)"
      ],
      "metadata": {
        "id": "DkdPCc6WqTlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = data[1:796]\n",
        "## DO NOT FORGET TO EDIT THE NUMBERS HERE AND ALSO NEGLECT ANY USEFUL PAGES"
      ],
      "metadata": {
        "id": "bb4IiEU9qkqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  you can optimize this prompt if you need but keep it with the smae format please :)\n",
        "\n",
        "prompt = \"\"\"\n",
        "\n",
        "Based on the following text, generate one Question and its corresponding Answer.\n",
        "For each question you formulate, provide a comprehensive answer with details immediately following the question, separated by a vertical bar \"|\" provide only 2-3 questions. The context to analyze is as follows: <Context> {context} </Context>.\n",
        "For Example :\n",
        "## Context:\n",
        "البعيد أو الغائي لقانون الإجراءات الجنائية يمثل ذات الهدف بالنسبة لكافة العلوم الجنائية.\n",
        "رابعاً - وظيفة قانون الإجراءات الجنائية:\n",
        "يمكن القول بأن الوظيفة الأساسية لهذا القانون هي تنظيم العدالة الجنائية؛ وتحقيق هذه\n",
        "الغاية يتطلب الموائمة بين اعتبارين. يتمثل الاعتبار الأول في وضع آلية يُمكن من خلالها\n",
        "تفعيل نصوص قانون العقوبات حماية للمصالح الاجتماعية العامة المتعددة، ويتجلى الاعتبار\n",
        "الثاني في ضمان حقوق الفرد وحريته في مواجهة السلطات الإجرائية الجنائية.\n",
        "\n",
        "# Your Response Sholud Be Like This format only do not add any thing else\n",
        "Question : وظيفة قانون الإجراءات الجنائية | يمكن القول بأن الوظيفة الأساسية لهذا القانون هي تنظيم العدالة الجنائية؛ وتحقيق هذه\n",
        "الغاية يتطلب الموائمة بين اعتبارين. يتمثل الاعتبار الأول في وضع آلية يُمكن من خلالها\n",
        "تفعيل نصوص قانون العقوبات حماية للمصالح الاجتماعية العامة المتعددة، ويتجلى الاعتبار\n",
        "الثاني في ضمان حقوق الفرد وحريته في مواجهة السلطات الإجرائية الجنائية.\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iLUTM7UBs2Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_api = [\n",
        "    \"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\",\n",
        "    \"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\",\n",
        "    \"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\",\n",
        "    \"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\",\n",
        "     \"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\",\n",
        "     \"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\",\n",
        "     \"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\",\n",
        "    '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',\n",
        "    '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',\n",
        "    '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',\n",
        "    \"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\",\n",
        "    \"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\",\n",
        "    \"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\"\n",
        "]\n",
        "\n",
        "# ADD YOUR APIs IN THE HEAD OF THE LIST"
      ],
      "metadata": {
        "id": "udWfbmBOs4yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to initialize the ChatGroq model with the current API key\n",
        "def initialize_llm(api_key):\n",
        "    return ChatGroq(\n",
        "        api_key=api_key,\n",
        "        model=\"llama-3.1-70b-versatile\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024\n",
        "    )"
      ],
      "metadata": {
        "id": "agobv6cmOqDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ChatGroq model with the first API key\n",
        "api_key_index = 0\n",
        "\n",
        "llm = initialize_llm(list_of_api[api_key_index])"
      ],
      "metadata": {
        "id": "ZXQ7FbFPOsV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results = []\n",
        "i = 0\n",
        "\n",
        "for doc in selected_data:\n",
        "    Final_prompt = prompt.format(context=doc.page_content)\n",
        "    messages = [HumanMessage(content=Final_prompt)]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = llm.invoke(messages)\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = str(e)\n",
        "            print(f\"Encountered an error: {error_message}\")\n",
        "\n",
        "            # Check if it's a rate limit error or service unavailable error\n",
        "            if 'rate limit' in error_message.lower() or '429' in error_message:\n",
        "                print(f\"################################## Rate limit reached for API key ################################## {list_of_api[api_key_index]}. Switching API key...\")\n",
        "                api_key_index = (api_key_index + 1) % len(list_of_api)\n",
        "                llm = initialize_llm(list_of_api[api_key_index])\n",
        "                time.sleep(2)  # Wait before retrying\n",
        "            elif '503' in error_message or 'Service Unavailable' in error_message:\n",
        "                print(\"Service is unavailable, retrying after a delay...\")\n",
        "                time.sleep(5)  # Longer wait time for service errors\n",
        "            else:\n",
        "                raise  # Raise other unexpected errors\n",
        "\n",
        "    # Split the response into individual question-answer pairs\n",
        "    qa_pairs = response.content.split(\"Question :\")\n",
        "    print(\"Counter:\", i)\n",
        "    i += 1\n",
        "\n",
        "    for qa in qa_pairs[1:]:  # Skip the first empty part\n",
        "        question_answer = qa.split(\" | \")\n",
        "        if len(question_answer) == 2:\n",
        "            question = question_answer[0].strip()\n",
        "            answer = question_answer[1].strip()\n",
        "            print(\"Question:\", question)\n",
        "            print(\"Answer:\", answer)\n",
        "\n",
        "            results.append({\n",
        "                \"context\": doc.page_content,\n",
        "                \"question\": question,\n",
        "                \"answer\": answer\n",
        "            })\n"
      ],
      "metadata": {
        "id": "UEZYU3MFt9Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert results to a DataFrame\n",
        "df = pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "HKlYBS5myVZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "bdB9GbFe3qPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "_vf0PTDH64Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Context:\\n\", df.loc[2, \"context\"])\n",
        "\n",
        "print(\"Question:\\n\", df.loc[2, \"question\"])\n",
        "print(\"Answer:\\n\", df.loc[2, \"answer\"])\n"
      ],
      "metadata": {
        "id": "m_rZz6pO3fKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#pd.set_option('display.max_colwidth', None)\n"
      ],
      "metadata": {
        "id": "esG2BayX55Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10)\n"
      ],
      "metadata": {
        "id": "KUCFLS3Z5xpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCAT THE DF WITH TH FINAL_DF\n",
        "\n",
        "final_df = pd.concat([final_df, df], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TaYOjS4h51Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "id": "9shmGW0GFebt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this cell after you finish all the pages of the book"
      ],
      "metadata": {
        "id": "u09rEdfKMFJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the book name\n",
        "\n",
        "\n",
        "final_df.to_csv(\"book name.csv\", index=False)\n",
        "\n",
        "files.download(\"book name.csv\")"
      ],
      "metadata": {
        "id": "xy5HfXm7MEqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89fe7b31-aea1-4991-b883-5b4a5c331594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33417a1c-ccba-46a4-b3cd-69ca793d1bf2\", \"\\u0627\\u062c\\u0631\\u0627\\u0621\\u0627\\u062a_\\u0627\\u0644\\u0645\\u062d\\u0627\\u0643\\u0645\\u0629_\\u0648\\u0637\\u0631\\u0642_\\u0627\\u0644\\u0637\\u0639\\u0646_\\u0641\\u0649_\\u0627\\u0644\\u0627\\u062d\\u0643\\u0627\\u0645_\\u0627\\u0644\\u0645\\u0635\\u0631\\u064a.csv\", 8102974)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}