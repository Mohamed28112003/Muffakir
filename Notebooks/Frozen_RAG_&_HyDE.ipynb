{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed28112003/Muffakir/blob/main/Notebooks/Frozen_RAG_%26_HyDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "bY5XOMBuA8Uv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bWmGd91a030"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install unstructured\n",
        "!pip install \"unstructured[pdf]\"\n",
        "!apt-get install -y poppler-utils\n",
        "!pip install LangChain -q\n",
        "!pip install langchain transformers\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install rank-bm25 sentence-transformers\n",
        "!pip uninstall nltk -y\n",
        "!pip install nltk\n",
        "!pip install openai\n",
        "!pip install groq\n",
        "!pip install langchain-groq\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzXFntYq8pys"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "import re\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "import gradio as gr\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import Document\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gt5ufyTkPPq"
      },
      "source": [
        "## **Load TXT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-3BXNRVxMkI"
      },
      "outputs": [],
      "source": [
        "data_loader = DirectoryLoader(\"/content/Data\",\n",
        "                             glob=\"*.txt\",\n",
        "                             show_progress=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter_recursive = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"Page number\"]\n",
        ")"
      ],
      "metadata": {
        "id": "G2UdWq4rqFxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_loader.load_and_split(text_splitter=text_splitter_recursive) # Load documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaWMKcinqIAg",
        "outputId": "ffeac1b4-c401-4f07-c42c-40b13dd8b6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:18<00:00, 13.83s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Documents : {len(data)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLa3P6NRRNOr",
        "outputId": "a29cc779-2831-4e2f-f9bd-d138638e00e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents : 3391.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Clean Text**"
      ],
      "metadata": {
        "id": "gUmSWUoaKwEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[9].page_content"
      ],
      "metadata": {
        "id": "TP2PknLyKu8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_arabic_text(text):\n",
        "    text = re.sub(r'Page number: \\d+', '', text)\n",
        "    text = re.sub(r'- \\d+ -', '', text)\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "for i in range(len(data)):\n",
        "    data[i].page_content = clean_arabic_text(data[i].page_content)\n"
      ],
      "metadata": {
        "id": "tZnvUF1JrUS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[9].page_content"
      ],
      "metadata": {
        "id": "8D8q5d3JK4aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTfS8mm05aif"
      },
      "source": [
        "## **Embeddding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxwZM_CvE0Qy"
      },
      "outputs": [],
      "source": [
        "base_model = SentenceTransformer('intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "path = \"/content/DB\"\n",
        "client = chromadb.PersistentClient(path=path)\n",
        "\n",
        "db_file = client.get_or_create_collection(name='Book',\n",
        "                                          metadata={\"hnsw:space\": \"cosine\"})"
      ],
      "metadata": {
        "id": "Xg9WQfTx7Dst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(texts):\n",
        "    return base_model.encode(texts)\n",
        "\n",
        "i = 0\n",
        "for chunk in data:\n",
        "    embeddings = embed([chunk.page_content])\n",
        "    db_file.add(\n",
        "        documents=[chunk.page_content],\n",
        "        metadatas=[chunk.metadata],\n",
        "        ids=[f\"chunk_{i}\"],\n",
        "        embeddings=embeddings  # Pass the embeddings directly\n",
        "    )\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "Bf7HWs3qumwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_file.get(ids=[\"chunk_2\"])"
      ],
      "metadata": {
        "id": "PU9LDUXvj4l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_documents_embeddings(query_embedding, k=10):\n",
        "    query_embedding_list = query_embedding.tolist()\n",
        "\n",
        "    results = db_file.query(\n",
        "        query_embeddings=[query_embedding_list],\n",
        "\n",
        "        n_results=k)\n",
        "    return results"
      ],
      "metadata": {
        "id": "1Gf7G2DU1hyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1AMya0p4jnD"
      },
      "source": [
        "## **LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igcRsKVGMgyF",
        "outputId": "96437c7e-50d4-4a68-be32-af5cceda7c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contentadditional_kwargsresponse_metadatatypenameidexampletool_callsinvalid_tool_callsusage_metadata"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "llm = ChatGroq(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"Hello\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "\n",
        "for chunk in response:\n",
        "    content = chunk[0] if isinstance(chunk, tuple) else chunk\n",
        "    print(content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLz-Nju8PM1f",
        "outputId": "52994ebd-baaa-4247-8ea1-2b0acb79a996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF-zgGCrPD4u"
      },
      "outputs": [],
      "source": [
        "#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"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Frozen RAG**"
      ],
      "metadata": {
        "id": "TOmxl6qb1vEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_HoYqI_Pb6q"
      },
      "outputs": [],
      "source": [
        "qna_template = \"\\n\".join([\n",
        "    \"Act as a knowledgeable law professor. Analyze the provided legal context and respond to the subsequent question with thoroughness and clarity. If the information needed to answer the question is not present in the context, respond with 'NO ANSWER IS AVAILABLE.'\",\n",
        "    \"give the answer in details with Arabic accent \",\n",
        "\n",
        "    \"### Context\",\n",
        "    \"{context}\",\n",
        "\n",
        "    \"### Question\",\n",
        "    \"{question}\",\n",
        "\n",
        "    \"### Answer:\",\n",
        "])\n",
        "\n",
        "qna_prompt = PromptTemplate(\n",
        "    template=qna_template,\n",
        "    input_variables=['context', 'question'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "stuff_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=qna_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample query\n",
        "query = ''''\n",
        "\n",
        "ما أهمية التنفيذ الجبري في قانون المرافعات؟\n",
        "\n",
        "'''\n",
        "\n",
        "query_embedding = base_model.encode(query)\n",
        "\n",
        "similar_documents = retrieve_documents_embeddings(query_embedding, k=7)\n",
        "\n"
      ],
      "metadata": {
        "id": "ADw5t1W1Zwod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = similar_documents['documents'][0]\n",
        "metadatas = similar_documents['metadatas'][0]\n",
        "\n",
        "from langchain.schema import Document\n",
        "formatted_documents = [\n",
        "    Document(page_content=doc, metadata=meta)\n",
        "    for doc, meta in zip(documents, metadatas)\n",
        "]"
      ],
      "metadata": {
        "id": "14vy04IW0D6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaMsiKJdJec4"
      },
      "outputs": [],
      "source": [
        "answer = stuff_chain(\n",
        "    {\n",
        "        \"input_documents\": formatted_documents,\n",
        "        \"question\": query\n",
        "    },\n",
        "    return_only_outputs=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_text = answer['output_text']\n",
        "\n",
        "print(\"Generated Answer:\")\n",
        "print(\"=\" * 50)\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "id": "qgf9zScIcNMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradio Frozen RAG**"
      ],
      "metadata": {
        "id": "uW2rbR3z8ou7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_answer(query):\n",
        "    query_embedding = base_model.encode(query)\n",
        "\n",
        "    similar_documents = retrieve_documents_embeddings(query_embedding, k=7)\n",
        "\n",
        "    documents = similar_documents['documents'][0]\n",
        "    metadatas = similar_documents['metadatas'][0]\n",
        "\n",
        "    formatted_documents = [\n",
        "        Document(page_content=doc, metadata=meta)\n",
        "        for doc, meta in zip(documents, metadatas)\n",
        "    ]\n",
        "    answer = stuff_chain(\n",
        "        {\n",
        "            \"input_documents\": formatted_documents,\n",
        "            \"question\": query\n",
        "        },\n",
        "        return_only_outputs=True,\n",
        "    )\n",
        "\n",
        "    output_text = answer['output_text']\n",
        "\n",
        "    similar_docs_str = \"\\n\".join([f\"**Document {i+1}:**\\n{doc}\\n**Metadata:** {meta}\" for i, (doc, meta) in enumerate(zip(documents, metadatas))])\n",
        "\n",
        "    return output_text, similar_docs_str\n",
        "\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_answer,\n",
        "    inputs=gr.Textbox(lines=5, placeholder=\"Enter your query here...\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Answer\"),\n",
        "        gr.Textbox(label=\"Similar Documents with Metadata\")\n",
        "    ],\n",
        "\n",
        "        examples=[\n",
        "        \"ما أهمية التنفيذ الجبري في قانون المرافعات؟\",\n",
        "        \"ما هي قواعد الاختصاص القضائي في القانون المصري؟\",\n",
        "    ],\n",
        "    title=\"Muffakir\",\n",
        "    description=\"Ask your questions\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "XTW3vIGu7qVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hypothetical Document Embeddings**\n"
      ],
      "metadata": {
        "id": "n8njMCAFskq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_hyde = ''''\n",
        "\n",
        "ما أهمية التنفيذ الجبري في قانون المرافعات؟\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "1kA5q1GM03AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template_hyde = \"\\n\".join([\n",
        "    \"Act as a Law professor from egypt. Analyze the provided law question and respond to the subsequent question with thoroughness and clarity.\",\n",
        "    \"give the answer in details in arabic only \",\n",
        "\n",
        "\n",
        "    \"### Question\",\n",
        "    \"{question}\",\n",
        "\n",
        "    \"### Answer:\",\n",
        "])\n",
        "prompt_hyde = ChatPromptTemplate.from_template(template_hyde)\n",
        "\n",
        "hypothetical_document = llm.invoke(prompt_hyde.format(question=query_hyde))\n"
      ],
      "metadata": {
        "id": "oyFfU_RH0iiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "hypothetical_document_embedding = base_model.encode(hypothetical_document.content)\n",
        "\n",
        "similar_documents_hyde = retrieve_documents_embeddings(hypothetical_document_embedding, k=5)\n",
        "\n",
        "\n",
        "\n",
        "documents_hyde = similar_documents_hyde['documents'][0]\n",
        "metadatas_hyde = similar_documents_hyde['metadatas'][0]\n",
        "\n",
        "from langchain.schema import Document\n",
        "formatted_documents_hyde = [\n",
        "    Document(page_content=doc, metadata=meta)\n",
        "    for doc, meta in zip(documents_hyde, metadatas_hyde)\n",
        "]\n"
      ],
      "metadata": {
        "id": "4wLIGiyi0jfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = stuff_chain(\n",
        "        {\n",
        "            \"input_documents\": formatted_documents_hyde ,\n",
        "            \"question\": query\n",
        "        },\n",
        "        return_only_outputs=True\n",
        "    )\n",
        "\n",
        "\n",
        "output_text = answer['output_text']\n",
        "\n",
        "# Print the formatted answer\n",
        "print(\"Generated Answer:\")\n",
        "print(\"=\" * 50)\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "id": "6s7XjcIjsiLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradio HyDE**"
      ],
      "metadata": {
        "id": "ud1RYUFBAwYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template_hyde = \"\\n\".join([\n",
        "    \"Act as a Law professor from Egypt. Analyze the provided law question and respond to the subsequent question with thoroughness and clarity.\",\n",
        "    \"give the answer in details in arabic only.\",\n",
        "\n",
        "    \"### Question\",\n",
        "    \"{question}\",\n",
        "\n",
        "    \"### Answer:\",\n",
        "])\n",
        "prompt_hyde = ChatPromptTemplate.from_template(template_hyde)\n",
        "\n",
        "def law_chatbot(query):\n",
        "    try:\n",
        "        hypothetical_document = llm.invoke(prompt_hyde.format(question=query))\n",
        "\n",
        "        hypothetical_document_embedding = base_model.encode(hypothetical_document.content)\n",
        "\n",
        "        similar_documents_hyde = retrieve_documents_embeddings(hypothetical_document_embedding, k=5)\n",
        "\n",
        "        documents_hyde = similar_documents_hyde['documents'][0]\n",
        "        metadatas_hyde = similar_documents_hyde['metadatas'][0]\n",
        "\n",
        "        formatted_documents_hyde = [\n",
        "            Document(page_content=doc, metadata=meta)\n",
        "            for doc, meta in zip(documents_hyde, metadatas_hyde)\n",
        "        ]\n",
        "\n",
        "        answer = stuff_chain(\n",
        "            {\n",
        "                \"input_documents\": formatted_documents_hyde,\n",
        "                \"question\": query\n",
        "            },\n",
        "            return_only_outputs=True\n",
        "        )\n",
        "\n",
        "        output_text = answer['output_text']\n",
        "\n",
        "        documents_display = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc}\" for i, doc in enumerate(documents_hyde)])\n",
        "        metadata_display = \"\\n\\n\".join([f\"Metadata {i+1}:\\n{meta}\" for i, meta in enumerate(metadatas_hyde)])\n",
        "\n",
        "        return output_text, documents_display, metadata_display\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", \"\", \"\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=law_chatbot,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Chatbot Answer\", lines=10),\n",
        "        gr.Textbox(label=\"Similar Documents\", lines=10),\n",
        "        gr.Textbox(label=\"Metadata\", lines=10),\n",
        "    ],\n",
        "\n",
        "\n",
        "        examples=[\n",
        "        \"ما أهمية التنفيذ الجبري في قانون المرافعات؟\",\n",
        "        \"ما هي قواعد الاختصاص القضائي في القانون المصري؟\",\n",
        "    ],\n",
        "\n",
        "    title=\"Muffakir HyDE \",\n",
        "    description=\"Ask any question\",\n",
        "\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "hEHego1e-7WL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7gt5ufyTkPPq"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}