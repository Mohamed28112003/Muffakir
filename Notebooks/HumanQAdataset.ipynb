{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed28112003/Muffakir/blob/main/Notebooks/HumanQAdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract text**"
      ],
      "metadata": {
        "id": "_xtPh2fgZTzm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q_JTinXfbv4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d3c48a-b51b-4e0c-98fa-1094cc0371ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-ai-formrecognizer\n",
            "  Downloading azure_ai_formrecognizer-3.3.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core>=1.23.0 (from azure-ai-formrecognizer)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer)\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting azure-common>=1.1 (from azure-ai-formrecognizer)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-formrecognizer) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2025.1.31)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-ai-formrecognizer)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer) (3.2.2)\n",
            "Downloading azure_ai_formrecognizer-3.3.3-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.4/301.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: azure-common, isodate, azure-core, msrest, azure-ai-formrecognizer\n",
            "Successfully installed azure-ai-formrecognizer-3.3.3 azure-common-1.1.28 azure-core-1.32.0 isodate-0.7.2 msrest-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-ai-formrecognizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# استبدل القيم الخاصة بك هنا\n",
        "endpoint = \"https://documentsfree.cognitiveservices.azure.com/\"\n",
        "api_key = \"8ec69b60270f4900b487ab5eabf265ac\"\n",
        "\n",
        "document_analysis_client = DocumentAnalysisClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(api_key)\n",
        ")\n",
        "\n",
        "\n",
        "with open(\"/content/أسئلة اللجنة السباعية للنيابة العامة دفعة 2020.pdf\", \"rb\") as document:\n",
        "    poller = document_analysis_client.begin_analyze_document(\n",
        "        model_id=\"prebuilt-layout\",  # يمكنك استخدام نماذج مخصصة أو النماذج الجاهزة مثل layout أو invoices\n",
        "        document=document\n",
        "    )\n",
        "\n",
        "result = poller.result()\n",
        "\n",
        "print(f\"Total pages: {len(result.pages)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp8ovpFKb9Nt",
        "outputId": "cd9c6d66-d422-4513-b132-8e7de1bc03f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pages: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"file_name.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
        "\n",
        "    print(f\"Total pages: {len(result.pages)}\", file=text_file)\n",
        "\n",
        "    for page in result.pages:\n",
        "        print(f\"\\nPage number: {page.page_number}\\n\", file=text_file)\n",
        "\n",
        "        for line in page.lines:\n",
        "            print(line.content, file=text_file)\n",
        "\n",
        "print(\"Text extracted and saved \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2RJLSS5ejr4",
        "outputId": "0dcc3057-a01d-44fb-eafa-9dd85cd3ddb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted and saved \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Text to QA**"
      ],
      "metadata": {
        "id": "63zRFhaMZRaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Function to preprocess text into QA dataset\n",
        "def preprocess_text(file_path):\n",
        "    qa_data = []\n",
        "    # unwanted_text = \"إهداء لروح والدى الراجى عفو ربه / المستشار السيد أحمد عبدالله إسماعيل\"\n",
        "    question_pattern = re.compile(r\"^س\\s*\\d+\\)\")  # Matches 'س' followed by a number and ')'\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        question, answer = \"\", \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line == unwanted_text or line.startswith(\"Page number\"):\n",
        "                continue\n",
        "\n",
        "            if question_pattern.match(line):\n",
        "                if question and answer:\n",
        "                    qa_data.append((question, answer.strip()))\n",
        "                question = line\n",
        "                answer = \"\"\n",
        "            else:\n",
        "                answer += \" \" + line\n",
        "\n",
        "        # Add the last Q&A pair\n",
        "        if question and answer:\n",
        "            qa_data.append((question, answer.strip()))\n",
        "\n",
        "    return qa_data\n",
        "\n",
        "text_file = \"/content/file_name.txt\"  # Update with your actual file text path\n",
        "qa_data = preprocess_text(text_file)\n",
        "\n",
        "csv_filename = \"qa_dataset2.csv\"\n",
        "\n",
        "with open(csv_filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"question\", \"answer\"])\n",
        "    writer.writerows(qa_data)\n",
        "\n",
        "print(f\"CSV file '{csv_filename}' has been created successfully!\")\n"
      ],
      "metadata": {
        "id": "LXGmf9gAgufD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}