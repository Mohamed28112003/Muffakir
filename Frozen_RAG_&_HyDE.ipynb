{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed28112003/Muffakir/blob/main/Frozen_RAG_%26_HyDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bWmGd91a030"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install unstructured\n",
        "!pip install \"unstructured[pdf]\"\n",
        "!apt-get install -y poppler-utils\n",
        "!pip install LangChain -q\n",
        "!pip install langchain transformers\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install rank-bm25 sentence-transformers\n",
        "!pip uninstall nltk -y\n",
        "!pip install nltk\n",
        "!pip install openai\n",
        "!pip install groq\n",
        "!pip install langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pzXFntYq8pys"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "import re\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gt5ufyTkPPq"
      },
      "source": [
        "# Load TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2-3BXNRVxMkI"
      },
      "outputs": [],
      "source": [
        "data_loader = DirectoryLoader(\"/content/Data\",\n",
        "                             glob=\"*.txt\",\n",
        "                             show_progress=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter_recursive = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Adjust chunk size based on content length\n",
        "    chunk_overlap=0,  # No overlap needed\n",
        "    separators=[\"Page number\"]  # Split at answer or next question\n",
        ")"
      ],
      "metadata": {
        "id": "G2UdWq4rqFxn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents from the specified directory\n",
        "data = data_loader.load_and_split(text_splitter=text_splitter_recursive) # Load documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaWMKcinqIAg",
        "outputId": "ffeac1b4-c401-4f07-c42c-40b13dd8b6d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:18<00:00, 13.83s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Documents : {len(data)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLa3P6NRRNOr",
        "outputId": "a29cc779-2831-4e2f-f9bd-d138638e00e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents : 3391.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove \"Page number \" from each chunk using regex\n",
        "for i in range(len(data)):\n",
        "  data[i].page_content = re.sub(r\"Page number: \\d+\", \"\", data[i].page_content)"
      ],
      "metadata": {
        "id": "tZnvUF1JrUS2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTfS8mm05aif"
      },
      "source": [
        "# Embeddding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxwZM_CvE0Qy"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the base model\n",
        "base_model = SentenceTransformer('intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "\n",
        "path = \"/content/DB\"\n",
        "client = chromadb.PersistentClient(path=path)\n",
        "\n",
        "db_file = client.get_or_create_collection(name='Book',\n",
        "                                          metadata={\"hnsw:space\": \"cosine\"})\n",
        "\n",
        "\n",
        "def embed(texts):\n",
        "    return base_model.encode(texts)\n",
        "\n",
        "i = 0\n",
        "for chunk in data:\n",
        "    embeddings = embed([chunk.page_content])  # Get embeddings using the base model\n",
        "    db_file.add(\n",
        "        documents=[chunk.page_content],\n",
        "        metadatas=[chunk.metadata],\n",
        "        ids=[f\"chunk_{i}\"],\n",
        "        embeddings=embeddings  # Pass the embeddings directly\n",
        "    )\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "Bf7HWs3qumwJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_file.get(ids=[\"chunk_2\"])"
      ],
      "metadata": {
        "id": "PU9LDUXvj4l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_documents_embeddings(query_embedding, k=10):\n",
        "    query_embedding_list = query_embedding.tolist()\n",
        "\n",
        "    results = db_file.query(\n",
        "        query_embeddings=[query_embedding_list],\n",
        "\n",
        "        n_results=k)\n",
        "    return results"
      ],
      "metadata": {
        "id": "1Gf7G2DU1hyz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1AMya0p4jnD"
      },
      "source": [
        "العب بقي من اول هنا 😲\n",
        "Prompt\n",
        "query\n",
        "model\n",
        "output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igcRsKVGMgyF",
        "outputId": "21cd308a-f1dd-4ccb-a045-8b7e4e947aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contentadditional_kwargsresponse_metadatatypenameidexampletool_callsinvalid_tool_callsusage_metadata"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage  # Import HumanMessage\n",
        "\n",
        "# Set the GROQ API Key as an environment variable\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),  # Retrieve the API key from the environment variable\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        ")\n",
        "\n",
        "# Create a list of messages using the HumanMessage class\n",
        "messages = [\n",
        "    HumanMessage(content=\"Hello\")\n",
        "]\n",
        "\n",
        "# Sending a message to the model\n",
        "response = llm.invoke(messages)  # Use invoke instead of call\n",
        "\n",
        "# Handle streaming response\n",
        "for chunk in response:\n",
        "    # Assuming the structure is (content, metadata), modify according to actual structure\n",
        "    content = chunk[0] if isinstance(chunk, tuple) else chunk\n",
        "    print(content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLz-Nju8PM1f",
        "outputId": "4d1c112c-7136-4605-89fb-94466fcc594b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF-zgGCrPD4u"
      },
      "outputs": [],
      "source": [
        "#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"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen RAG"
      ],
      "metadata": {
        "id": "TOmxl6qb1vEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "m_HoYqI_Pb6q"
      },
      "outputs": [],
      "source": [
        "qna_template = \"\\n\".join([\n",
        "    \"Act as a knowledgeable law professor. Analyze the provided legal context and respond to the subsequent question with thoroughness and clarity. If the information needed to answer the question is not present in the context, respond with 'NO ANSWER IS AVAILABLE.'\",\n",
        "    \"give the answer in details with Arabic accent \",\n",
        "\n",
        "    \"### Context\",\n",
        "    \"{context}\",\n",
        "\n",
        "    \"### Question\",\n",
        "    \"{question}\",\n",
        "\n",
        "    \"### Answer:\",\n",
        "])\n",
        "\n",
        "qna_prompt = PromptTemplate(\n",
        "    template=qna_template,\n",
        "    input_variables=['context', 'question'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "stuff_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=qna_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample query\n",
        "query = ''''\n",
        "\n",
        "ما أهمية التنفيذ الجبري في قانون المرافعات؟\n",
        "\n",
        "'''\n",
        "\n",
        "# Generate the embedding for the query\n",
        "query_embedding = base_model.encode(query)\n",
        "\n",
        "# Perform similarity search in ChromaDB\n",
        "similar_documents = retrieve_documents_embeddings(query_embedding, k=7)\n",
        "\n"
      ],
      "metadata": {
        "id": "ADw5t1W1Zwod"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = similar_documents['documents'][0]\n",
        "metadatas = similar_documents['metadatas'][0]\n",
        "\n",
        "from langchain.schema import Document\n",
        "formatted_documents = [\n",
        "    Document(page_content=doc, metadata=meta)\n",
        "    for doc, meta in zip(documents, metadatas)\n",
        "]"
      ],
      "metadata": {
        "id": "14vy04IW0D6h"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OaMsiKJdJec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae9b130-390e-4c65-9ae5-b6ccb415417b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer: {'output_text': 'أهمية التنفيذ الجبري في قانون المرافعات تكمن في كونه الوسيلة التي يمكن من خلالها للدائن الحصول على حقه في حالة رفض المدين طواعية الوفاء بما عليه من التزامات. يعتبر التنفيذ الجبري آخر واخطر مراحل الصراع حول الحق بين الدائن والمدين، ويتطلب تدخل المشرع لتنظيم إجراءات خصومة التنفيذ بما يحقق المصالح الخاصة بأطراف هذه الخصومة، مع مراعاة الصالح العام للمحافظة على النظام القانوني للدولة.\\n\\nأهمية التنفيذ الجبري يمكن تلخيصها في النقاط التالية:\\n\\n1.  **حماية الحقوق**: التنفيذ الجبري يهدف إلى حماية الحقوق أو المراكز الموضوعية الثابتة في السندات التنفيذية، وضمان تنفيذها في ظل غياب إرادة المدين.\\n2.  **تحقيق العدالة**: التنفيذ الجبري يعمل على تحقيق العدالة بين أطراف الخصومة، من خلال ضمان حصول كل ذي حق على حقه.\\n3.  **استقرار المعاملات القانونية**: التنفيذ الجبري يساهم في استقرار المعاملات القانونية، ويرسخ الثقة بين الأفراد والمؤسسات.\\n4.  **ضمان تنفيذ الأحكام**: التنفيذ الجبري يضمن تنفيذ الأحكام القضائية، ويعمل على حماية حقوق الدائنين.\\n5.  **تحقيق المواطنة**: التنفيذ الجبري يعمل على تحقيق المواطنة، وضمان حصول كل فرد على حقوقه وتحقيق العدالة.\\n\\nفي الخلاصة، التنفيذ الجبري يعتبر ركيزة أساسية في قانون المرافعات، ويلعب دوراً حيوياً في حماية الحقوق وتحقيق العدالة وضمان استقرار المعاملات القانونية.'}\n"
          ]
        }
      ],
      "source": [
        "# Use the stuff chain to generate the answer\n",
        "answer = stuff_chain(\n",
        "    {\n",
        "        \"input_documents\": formatted_documents,  # Pass the search results directly\n",
        "        \"question\": query  # Pass the original query\n",
        "    },\n",
        "    return_only_outputs=True,  # Return only the output from the chain\n",
        ")\n",
        "\n",
        "# Print the answer\n",
        "print(\"Generated Answer:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the output text from the answer\n",
        "output_text = answer['output_text']\n",
        "\n",
        "# Print the formatted answer\n",
        "print(\"Generated Answer:\")\n",
        "print(\"=\" * 50)  # Separator line\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgf9zScIcNMt",
        "outputId": "c5c5e086-956c-45d2-a8db-9694a027d603"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer:\n",
            "==================================================\n",
            "أهمية التنفيذ الجبري في قانون المرافعات تكمن في كونه الوسيلة التي يمكن من خلالها للدائن الحصول على حقه في حالة رفض المدين طواعية الوفاء بما عليه من التزامات. يعتبر التنفيذ الجبري آخر واخطر مراحل الصراع حول الحق بين الدائن والمدين، ويتطلب تدخل المشرع لتنظيم إجراءات خصومة التنفيذ بما يحقق المصالح الخاصة بأطراف هذه الخصومة، مع مراعاة الصالح العام للمحافظة على النظام القانوني للدولة.\n",
            "\n",
            "أهمية التنفيذ الجبري يمكن تلخيصها في النقاط التالية:\n",
            "\n",
            "1.  **حماية الحقوق**: التنفيذ الجبري يهدف إلى حماية الحقوق أو المراكز الموضوعية الثابتة في السندات التنفيذية، وضمان تنفيذها في ظل غياب إرادة المدين.\n",
            "2.  **تحقيق العدالة**: التنفيذ الجبري يعمل على تحقيق العدالة بين أطراف الخصومة، من خلال ضمان حصول كل ذي حق على حقه.\n",
            "3.  **استقرار المعاملات القانونية**: التنفيذ الجبري يساهم في استقرار المعاملات القانونية، ويرسخ الثقة بين الأفراد والمؤسسات.\n",
            "4.  **ضمان تنفيذ الأحكام**: التنفيذ الجبري يضمن تنفيذ الأحكام القضائية، ويعمل على حماية حقوق الدائنين.\n",
            "5.  **تحقيق المواطنة**: التنفيذ الجبري يعمل على تحقيق المواطنة، وضمان حصول كل فرد على حقوقه وتحقيق العدالة.\n",
            "\n",
            "في الخلاصة، التنفيذ الجبري يعتبر ركيزة أساسية في قانون المرافعات، ويلعب دوراً حيوياً في حماية الحقوق وتحقيق العدالة وضمان استقرار المعاملات القانونية.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothetical Document Embeddings\n"
      ],
      "metadata": {
        "id": "n8njMCAFskq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample query\n",
        "query_hyde = ''''\n",
        "\n",
        "ما أهمية التنفيذ الجبري في قانون المرافعات؟\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "1kA5q1GM03AW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothetical Document Embeddings\n",
        "\n",
        "\n",
        "# reusing the question and vectorstore as earlier\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# HyDE document genration prompt\n",
        "template_hyde = \"\\n\".join([\n",
        "    \"Act as a Law professor from egypt. Analyze the provided law question and respond to the subsequent question with thoroughness and clarity.\",\n",
        "    \"give the answer in details in arabic only \",\n",
        "\n",
        "\n",
        "    \"### Question\",\n",
        "    \"{question}\",\n",
        "\n",
        "    \"### Answer:\",\n",
        "])\n",
        "prompt_hyde = ChatPromptTemplate.from_template(template_hyde)\n",
        "\n",
        "# generating a hypothetical document based on the user input\n",
        "hypothetical_document = llm.invoke(prompt_hyde.format(question=query_hyde))\n"
      ],
      "metadata": {
        "id": "oyFfU_RH0iiG"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Generate the embedding for the query\n",
        "hypothetical_document_embedding = base_model.encode(hypothetical_document.content)\n",
        "\n",
        "# Perform similarity search in ChromaDB\n",
        "similar_documents_hyde = retrieve_documents_embeddings(hypothetical_document_embedding, k=5)\n",
        "\n",
        "\n",
        "\n",
        "documents_hyde = similar_documents_hyde['documents'][0]\n",
        "metadatas_hyde = similar_documents_hyde['metadatas'][0]\n",
        "\n",
        "from langchain.schema import Document\n",
        "formatted_documents_hyde = [\n",
        "    Document(page_content=doc, metadata=meta)\n",
        "    for doc, meta in zip(documents_hyde, metadatas_hyde)\n",
        "]\n"
      ],
      "metadata": {
        "id": "4wLIGiyi0jfW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = stuff_chain(\n",
        "        {\n",
        "            \"input_documents\": formatted_documents_hyde ,\n",
        "            \"question\": query\n",
        "        },\n",
        "        return_only_outputs=True\n",
        "    )\n",
        "\n",
        "\n",
        "# Get the output text from the answer\n",
        "output_text = answer['output_text']\n",
        "\n",
        "# Print the formatted answer\n",
        "print(\"Generated Answer:\")\n",
        "print(\"=\" * 50)  # Separator line\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s7XjcIjsiLQ",
        "outputId": "1290cb1b-9eb7-44da-8a6a-40475bc98b0b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer:\n",
            "==================================================\n",
            "بسم الله الرحمن الرحيم، أستاذي العزيز، سأجيب على سؤالك عن أهمية التنفيذ الجبري في قانون المرافعات.\n",
            "\n",
            "هذا السؤال يتطلب منا أن نكشف عن أهمية التنفيذ الجبري في قانون المرافعات، ويتعلق ذلك بمفهوم وقواعد التنفيذ الجبري.\n",
            "\n",
            "بالنسبة لي، أستاذي، أهمية التنفيذ الجبري في قانون المرافعات تكمن فيما يأتي:\n",
            "\n",
            "أولاً، التنفيذ الجبري هو الوسيلة التي يمكن من خلالها للدائن الحصول على حقه في حالة رفض المدين طواعية الوفاء بما عليه من التزامات. وهذا يعني أن التنفيذ الجبري يضمن للفرد حقه في الحصول على ما له من حقوقه القانونية.\n",
            "\n",
            "ثانياً، التنفيذ الجبري يعتبر الوسيلة التي يمكن من خلالها إعمال جزاء مخالفة القانون على الواقع. وهذا يعني أن التنفيذ الجبري يضمن للمجتمع تطبيق القانون وتحقيق العدالة.\n",
            "\n",
            "ثالثاً، التنفيذ الجبري يضمن للمدين حماية من استغلال الدائن له. وهذا يعني أن التنفيذ الجبري يضمن للمدين حقوقه القانونية وتحقيق العدالة في التعاملات القانونية.\n",
            "\n",
            "رابعاً، التنفيذ الجبري يعتبر وسيلة لتكامل النظام القانوني للدولة. وهذا يعني أن التنفيذ الجبري يضمن للمجتمع تطبيق القانون وتحقيق العدالة.\n",
            "\n",
            "وأخيراً، أستاذي، أهمية التنفيذ الجبري تكمن في دورها في تحقيق المصالح الخاصة لأطراف الخصومة، مع مراعاة الصالح العام للمحافظة على النظام القانوني للدولة.\n",
            "\n",
            "ختاماً، أستاذي العزيز، أهمية التنفيذ الجبري في قانون المرافعات تكمن في ضمان حقوق الفرد وتحقيق العدالة في التعاملات القانونية، وتطبيق القانون، وحماية المدين من استغلال الدائن له، وتكامل النظام القانوني للدولة.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0KN3yKgQgSv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Data/حقوق /عين شمس /رابعه/CSV/التنفيذ_الجبري_الجزء_الثاني_القائم_بالتدريس_د_سيد_أبو_سريع.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "yqfUa44XiTW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(\"Context:\\n\", df.loc[2, \"context\"])\n",
        "\n",
        "print(\"Question:\\n\", df.loc[2, \"question\"])\n",
        "print(\"Answer:\\n\", df.loc[2, \"answer\"])\n"
      ],
      "metadata": {
        "id": "U987gaAciaN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}